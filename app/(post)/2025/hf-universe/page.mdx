export const metadata = {
  title: 'Welcome to the Hugging-Verse',
  description: 'A quick guide to what Hugging Face is',
  openGraph: {
    title: 'Welcome to the Hugging-Verse',
    description: 'A quick guide to what Hugging Face is',
    images: [{ url: '/og/hf-universe' }]
  }
}

<FloatingTOC
  items={[
    { text: "libraries", href: "#libraries" },
    { text: "hub", href: "#hub" },
    { text: "huggingchat", href: "#huggingchat" },
    { text: "research", href: "#research" },
    { text: "courses", href: "#courses" }
  ]}
/>

I often see people ask, *what is Hugging Face*? The most common answer is usually some variant of "Hugging Face is the GitHub of machine learning".

It is a good one-liner considering the breadth of Hugging Face's quest to **enable collaborative machine learning (ML)**. But it also hides the depth of what we do. The Hugging Face ecosystem, or Hugging-Verse, is quite expansive and it can often feel like we're doing too much without a strong focus.

But I believe the Hugging-Verse needs to be expansive precisely because we're pursuing such an ambitious quest.

<Figure>
  <img className="rounded-xl" src="/images/hf-universe.png" alt="The Hugging-Verse" />
  <Caption>Image generated from the <a href="https://huggingface.co/linoyts/huggy_flux_fal_lora">linoyts/huggy_flux_fal_lora</a> checkpoint.</Caption>
</Figure>

Think about games like Baldur's Gate 3 or Elden Ring. They're enormous games you can easily spend 100+ hours on in a single playthrough. Alongside the main quest, there are many side quests that add a ton of richness, worldbuilding, and depth.

Similarly, the main Hugging Face libraries and Hub platform advance the main quest. All the other libraries, research projects, courses, tools and services are side quests that enrich the Hugging-Verse.

It can be overwhelming if you're new though, so here is my high-level walkthrough.

<Tip>If you only take one thing away, remember, side quests are *optional*. Focus on a main library like Transformers and using the Hub at first if you aren't sure where to start.</Tip>

## libraries [#libraries]

The Hugging-Verse contains many libraries related to nearly every aspect of ML.

The main ones, like Transformers and Diffusers, provide access to pretrained models for inference and fine-tuning. They're able to do a little bit of everything.

Side libraries focus on specific ML topics such as:

- distributed training (Accelerate, picotron, nanotron)
- evaluation (Lighteval)
- on-device (Transformers.js, Optimum)

Where you start in the Hugging-Verse depends on what you're trying to do. There aren't defined progression paths.

Two general routes I think most people take are:

1. Start learning ML with Transformers.
2. Adapting a side library for their own work or research.

My recommendation is to pick 1 if you're a beginner. Otherwise, feel free to create your own progression path.

## hub [#hub]

The [Hub](https://hf.co/) is the most visible part of Hugging Face. This is probably what most people think of when they think of Hugging Face.

It is a Git-based platform with to access or share models, datasets, and Spaces. Every public repository provides free storage for your ML artifacts. Storage is based on [Xet](https://huggingface.co/blog/xet-on-the-hub), a more efficient storage system. Social features like [posts](https://huggingface.co/?post=true), [articles](https://huggingface.co/new-blog), and the Community tab encourage collaboration and discussion.

[Model](https://huggingface.co/models) repositories include a widget to run inference with a model on your browser. The widget is powered by [Inference Providers](https://huggingface.co/docs/api-inference/index) like Replicate and fal.

[Dataset](https://huggingface.co/datasets) repositories have a [Dataset Viewer](https://huggingface.co/docs/hub/datasets-viewer) for easily previewing a datasets contents. You can run SQL queries (or ask AI to craft a SQL query for you) on the dataset with the [Data Studio](https://huggingface.co/docs/hub/datasets-viewer) feature to explore it in more detail. Again, this all takes place in the browser.

<Tweet
    id="1894432966077468955"
/>

[Spaces](https://huggingface.co/spaces) is a scaffold to create and deploy ML apps with Gradio, Docker, React, Svelte, and more. A free tier Space runs on a basic 16GB CPU, but you can upgrade to more powerful GPUs and persistent storage if your app needs it. PRO subscribers have access to [ZeroGPU](https://huggingface.co/docs/hub/spaces-zerogpu), a shared cluster of A100 GPUs that are automatically allocated to a Space to complete a workload and then released to the next Space.

<Figure>
  <img className="rounded-xl" src="https://cdn-uploads.huggingface.co/production/uploads/5f17f0a0925b9863e28ad517/naVZI-v41zNxmGlhEhGDJ.gif" alt="ZeroGPU" />
</Figure>

## huggingchat [#huggingchat]

[HuggingChat](https://huggingface.co/chat/) is an open version of ChatGPT, providing access to some of the latest models like DeepSeek-R1. It uses a router, Omni, to automatically select the best route and model for a message. The system prompt of each model is modifiable.

HuggingChat is powered by Inference Providers, but you can use a different provider like [OpenRouter](https://openrouter.ai/docs/quickstart).

## research [#research]

Hugging Face is also engaged in research projects that empower the entire ML ecosystem. The goal isn't necessarily to train the best models. Instead, we're trying to create new and interesting research that benefits everyone.

Collaboration >>> competition.

As an example, the [The Ultra-Scale Playbook](http://hf.co/spaces/nanotron/ultrascale-playbook) is a culmination of everything the research team has learned about distributed training. It is freely available to anyone who is interested in scaling training of large language models to thousands of GPUs.

<Tweet
    id="1892273133547078036"
/>

Some other research projects include:

- [open-r1](https://huggingface.co/blog/open-r1): fully reproduce the DeepSeek-R1 model, an open and powerful reasoning model comparable to the OpenAI o-series models.
- [SmolLM](https://huggingface.co/HuggingFaceTB): release high-quality pretraining datasets (FineWeb, Cosmopedia) and small language and vision language models.

These types of projects enable other researchers to build on top of our work and push the field forward together.

## courses [#courses]

Educational content, such as the courses and cookbook, at [hf.co/learn](hf.co/learn) provide an accessible starting point for learning ML. A large part of our quest hinges on lowering the barrier for everyone to learn ML and convert them into active participants.

There are several courses - agents, reinforcement learning, diffusion, etc. - available on hf.co/learn. You can also find more courses, such as [quantization fundamentals](https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/), we collaborated on with other learning platforms like DeepLearning.AI.